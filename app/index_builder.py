import os
import json
import re
import faiss
import numpy as np
from typing import List
from app.embedder import embed_texts  # âœ… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† embedder.py

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_DIR = os.path.join(BASE_DIR, "Data")
INDEXES_DIR = os.path.join(BASE_DIR, "Indexes")


# --------------------------------------------
# ğŸ§© Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø©
# --------------------------------------------
def get_nested_value(data: dict, key_path: str):
    keys = key_path.split(".")
    for key in keys:
        if isinstance(data, dict):
            data = data.get(key, "")
        elif isinstance(data, list) and len(data) > 0:
            if isinstance(data[0], dict):
                data = data[0].get(key, "")
            else:
                return " ".join(map(str, data))
        else:
            return ""
    return str(data) if data else ""


# --------------------------------------------
# âœ‚ï¸ Ø¯Ø§Ù„Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ
# --------------------------------------------
def chunk_text(text: str, size: int = 300, overlap: int = 50) -> List[str]:
    if not text:
        return []
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        end = min(start + size, len(words))
        chunk = " ".join(words[start:end])
        chunks.append(chunk)
        start += size - overlap
    return chunks


# --------------------------------------------
# ğŸ—ï¸ Ø¯Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø¹Ø§Ù… Ù„Ø£ÙŠ Ù†ÙˆØ¹ Ø¨ÙŠØ§Ù†Ø§Øª
# --------------------------------------------
def build_faiss_index_for_json(data_list, index_name, text_function):
    """
    data_list: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (list of dicts)
    index_name: Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù†Ø§ØªØ¬ (Ù…Ø«Ù„ products_index)
    text_function: Ø¯Ø§Ù„Ø© Ù„ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø¹Ù†ØµØ± Ø¥Ù„Ù‰ Ù†Øµ
    """
    docs, metas = [], []

    for i, item in enumerate(data_list):
        combined_text = text_function(item)
        for j, chunk in enumerate(chunk_text(combined_text)):
            if chunk.strip():
                docs.append(chunk)
                metas.append({
                    "source_id": item.get("id", i),
                    "chunk_index": j,
                    "original": item
                })

    if not docs:
        raise ValueError(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØµÙˆØµ ÙŠÙ…ÙƒÙ† ÙÙ‡Ø±Ø³ØªÙ‡Ø§ ÙÙŠ {index_name}")

    embeddings = embed_texts(docs)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ÙÙ‡Ø±Ø³
    index_dir = os.path.join(INDEXES_DIR, index_name)
    os.makedirs(index_dir, exist_ok=True)

    faiss.write_index(index, os.path.join(index_dir, "index.faiss"))
    with open(os.path.join(index_dir, "meta.json"), "w", encoding="utf-8") as f:
        json.dump({"docs": docs, "metas": metas}, f, ensure_ascii=False, indent=2)

    print(f"âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {index_name} (Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹={len(docs)}, Ø£Ø¨Ø¹Ø§Ø¯={dim})")


# --------------------------------------------
# ğŸ§± 1. ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Products
# --------------------------------------------
def make_product_text(item):
    text = f"""
    Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬: {item.get('name', '')}.
    Ø§Ù„ÙˆØµÙ: {item.get('description', '')}.
    Ø§Ù„ÙØ¦Ø©: {item.get('category', '')}.
    Ø§Ù„Ø³Ø¹Ø±: {item.get('price', '')}.
    Ù†Ø³Ø¨Ø© Ø§Ù„Ø®ØµÙ…: {item.get('discountPercentage', '')}%.
    Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ®ØµÙŠØµ: {'Ù†Ø¹Ù…' if item.get('isCustomizable', False) else 'Ù„Ø§'}.
    """

    brand = item.get("brand", {})
    if brand:
        text += f"""
        Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯: {brand.get('displayName', '')}.
        ÙˆØµÙ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯: {brand.get('description', '')}.
        Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØ«ÙŠÙ‚: {brand.get('verificationStatus', '')}.
        """

    reels = item.get("reels", [])
    for reel in reels:
        text += f"""
        ÙÙŠØ¯ÙŠÙˆ ØªØ±ÙˆÙŠØ¬ÙŠ Ø¨Ø¹Ø¯Ø¯ Ù„Ø§ÙŠÙƒØ§Øª {reel.get('numOfLikes', 0)} 
        ÙˆÙ…Ø´Ø§Ù‡Ø¯Ø§Øª {reel.get('numOfWatches', 0)}.
        Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {reel.get('videoUrl', '')}.
        """

    return text


# --------------------------------------------
# ğŸ§± 2. ÙÙ‡Ø±Ø³ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯Ø§Øª Brands
# --------------------------------------------
def make_brand_text(item):
    html_text = item.get("returnPolicyAsHtml", "")
    clean_policy = re.sub(r"<[^>]+>", " ", html_text)
    clean_policy = re.sub(r"\s+", " ", clean_policy).strip()

    text = f"""
    Ø§Ø³Ù… Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯: {item.get('displayName', '')}.
    Ø§Ù„ÙˆØµÙ: {item.get('description', '')}.
    Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØ«ÙŠÙ‚: {item.get('verificationStatus', '')}.
    Ø´Ø¹Ø§Ø± Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯: {item.get('logoUrl', '')}.
    Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹: {clean_policy}.
    """

    products = item.get("products", [])
    if products:
        text += f"\nÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯ Ø¹Ù„Ù‰ {len(products)} Ù…Ù†ØªØ¬Ù‹Ø§:\n"
        for product in products:
            text += f"""
            ğŸ”¸ Ø§Ù„Ù…Ù†ØªØ¬: {product.get('name', '')}
            Ø§Ù„ÙˆØµÙ: {product.get('description', '')}
            Ø§Ù„ÙØ¦Ø©: {product.get('category', '')}
            Ø§Ù„Ø³Ø¹Ø±: {product.get('price', '')}
            Ù†Ø³Ø¨Ø© Ø§Ù„Ø®ØµÙ…: {product.get('discountPercentage', 0)}%
            Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ®ØµÙŠØµ: {'Ù†Ø¹Ù…' if product.get('isCustomizable', False) else 'Ù„Ø§'}.
            """

            reels = product.get("reels", [])
            if reels:
                text += f"\nğŸ“¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙŠÙ„Ø²: {len(reels)}\n"
                for reel in reels:
                    text += f"""
                    Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø¨Ø§Øª: {reel.get('numOfLikes', 0)}
                    Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª: {reel.get('numOfWatches', 0)}
                    Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {reel.get('videoUrl', '')}
                    """

    return text


# --------------------------------------------
# ğŸ§± 3. ÙÙ‡Ø±Ø³ Ø§Ù„Ø±ÙŠÙ„Ø² Reels
# --------------------------------------------
def make_reel_text(item):
    brand = item.get("brand", {})
    product = item.get("product", {})

    text = f"""
    ğŸ¥ ÙÙŠØ¯ÙŠÙˆ ØªØ±ÙˆÙŠØ¬ÙŠ
    Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø¨Ø§Øª: {item.get('numOfLikes', 0)}.
    Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª: {item.get('numOfWatches', 0)}.
    Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {item.get('videoUrl', '')}.
    Ø§Ù„Ù…Ù†ØªØ¬: {product.get('name', '')}.
    Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯: {brand.get('displayName', '')}.
    """
    return text


# --------------------------------------------
# ğŸš€ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# --------------------------------------------
if __name__ == "__main__":
    # ğŸ›ï¸ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
    products_path = os.path.join(DATA_DIR, "products.json")
    if os.path.exists(products_path):
        with open(products_path, "r", encoding="utf-8") as f:
            products_data = json.load(f)
        build_faiss_index_for_json(products_data, "products_index", make_product_text)

    # ğŸ·ï¸ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯Ø§Øª
    brands_path = os.path.join(DATA_DIR, "brands.json")
    if os.path.exists(brands_path):
        with open(brands_path, "r", encoding="utf-8") as f:
            brands_data = json.load(f)
        build_faiss_index_for_json(brands_data, "brands_index", make_brand_text)

    # ğŸ¥ Ø§Ù„Ø±ÙŠÙ„Ø²
    reels_path = os.path.join(DATA_DIR, "reels.json")
    if os.path.exists(reels_path):
        with open(reels_path, "r", encoding="utf-8") as f:
            reels_data = json.load(f)
        build_faiss_index_for_json(reels_data, "reels_index", make_reel_text)

    print("\nğŸ¯ ØªÙ… Ø¨Ù†Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø¨Ù†Ø¬Ø§Ø­!")
