
import os
import json
import faiss
import numpy as np
from typing import List
from app.embedder import embed_texts

# ุงููุณุงุฑุงุช ุงูุฃุณุงุณูุฉ
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_DIR = os.path.join(BASE_DIR, "Data")
INDEXES_DIR = os.path.join(BASE_DIR, "Indexes")


# --------------------------------------------
# ๐งฉ ุฏุงูุฉ ุงุณุชุฎุฑุงุฌ ุงูููู ุงููุชุฏุงุฎูุฉ (Nested Keys)
# --------------------------------------------
def get_nested_value(data: dict, key_path: str):
    """ูุฏุนู ุงููุตูู ุฅูู ุงูุญููู ุงููุชุฏุงุฎูุฉ ูุซู brand.displayName ุฃู reels.videoUrl"""
    keys = key_path.split(".")
    for key in keys:
        if isinstance(data, dict):
            data = data.get(key, "")
        elif isinstance(data, list) and len(data) > 0:
            if isinstance(data[0], dict):
                data = data[0].get(key, "")
            else:
                return " ".join(map(str, data))
        else:
            return ""
    return str(data) if data else ""


# --------------------------------------------
# โ๏ธ ุฏุงูุฉ ุชูุณูู ุงููุตูุต ุฅูู ุฃุฌุฒุงุก (Chunks)
# --------------------------------------------
def chunk_text(text: str, size: int = 300, overlap: int = 50) -> List[str]:
    """
    ุชูุณูู ุงููุต ุฅูู ููุงุทุน ุตุบูุฑุฉ ูุชูููู ููุฏุงู ุงููุนูู ุฃุซูุงุก ุชูููุฏ ุงูู embeddings
    """
    if not text:
        return []
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        end = min(start + size, len(words))
        chunk = " ".join(words[start:end])
        chunks.append(chunk)
        start += size - overlap
    return chunks


# --------------------------------------------
# ๐๏ธ ุจูุงุก ููุฑุณ FAISS ูููู JSON ูุญุฏุฏ
# --------------------------------------------
def build_faiss_index_for_json(json_filename: str, index_name: str, text_fields=None):
    """
    ูุจูู ููุฑุณ ูุชุฌูู ุจุงุณุชุฎุฏุงู FAISS ูู ุจูุงูุงุช JSON.
    text_fields: ูุงุฆูุฉ ุงูุญููู ุงูุชู ุณูุชู ุชุญููููุง ุฅูู ูุตูุต (ุชุฏุนู ุงูููุงุชูุญ ุงููุชุฏุงุฎูุฉ)
    """
    path = os.path.join(DATA_DIR, json_filename)
    if not os.path.exists(path):
        raise FileNotFoundError(f"โ ุงูููู ุบูุฑ ููุฌูุฏ: {path}")

    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    docs, metas = [], []

    for item in data:
        # ุฏูุฌ ุงูุญููู ุงููุทููุจุฉ
        if text_fields:
            combined_text = " \n ".join([get_nested_value(item, f) for f in text_fields])
        else:
            combined_text = " \n ".join([
                str(item.get(k, "")) for k in ["name", "description", "caption", "brand_name"] if item.get(k)
            ])

        # ุชูุทูุน ุงููุตูุต ุงูุทูููุฉ
        for i, chunk in enumerate(chunk_text(combined_text)):
            if chunk.strip():
                docs.append(chunk)
                metas.append({
                    "source_id": item.get("id"),
                    "chunk_index": i,
                    "original": item
                })

    if not docs:
        raise ValueError(f"โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุตูุต ูููู ููุฑุณุชูุง ูู {json_filename}")

    # ๐ง ุฅูุดุงุก ุงููุชุฌูุงุช ุจุงุณุชุฎุฏุงู embedder
    embeddings = embed_texts(docs)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)

    # ุญูุธ ุงูููุฑุณ ูุงูุจูุงูุงุช
    index_dir = os.path.join(INDEXES_DIR, index_name)
    os.makedirs(index_dir, exist_ok=True)
    faiss.write_index(index, os.path.join(index_dir, "index.faiss"))
    with open(os.path.join(index_dir, "meta.json"), "w", encoding="utf-8") as f:
        json.dump({"docs": docs, "metas": metas}, f, ensure_ascii=False, indent=2)

    print(f"โ ุชู ุจูุงุก ุงูููุฑุณ: {json_filename} -> {index_dir} (ุนุฏุฏ ุงููุชุฌูุงุช={len(docs)}, ุงูุฃุจุนุงุฏ={dim})")

